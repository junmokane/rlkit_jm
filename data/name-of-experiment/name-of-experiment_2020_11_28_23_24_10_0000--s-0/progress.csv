Epoch,evaluation/Actions Max,evaluation/Actions Mean,evaluation/Actions Min,evaluation/Actions Std,evaluation/Average Returns,evaluation/Num Paths,evaluation/Returns Max,evaluation/Returns Mean,evaluation/Returns Min,evaluation/Returns Std,evaluation/Rewards Max,evaluation/Rewards Mean,evaluation/Rewards Min,evaluation/Rewards Std,evaluation/env_infos/final/reward_ctrl Max,evaluation/env_infos/final/reward_ctrl Mean,evaluation/env_infos/final/reward_ctrl Min,evaluation/env_infos/final/reward_ctrl Std,evaluation/env_infos/final/reward_run Max,evaluation/env_infos/final/reward_run Mean,evaluation/env_infos/final/reward_run Min,evaluation/env_infos/final/reward_run Std,evaluation/env_infos/initial/reward_ctrl Max,evaluation/env_infos/initial/reward_ctrl Mean,evaluation/env_infos/initial/reward_ctrl Min,evaluation/env_infos/initial/reward_ctrl Std,evaluation/env_infos/initial/reward_run Max,evaluation/env_infos/initial/reward_run Mean,evaluation/env_infos/initial/reward_run Min,evaluation/env_infos/initial/reward_run Std,evaluation/env_infos/reward_ctrl Max,evaluation/env_infos/reward_ctrl Mean,evaluation/env_infos/reward_ctrl Min,evaluation/env_infos/reward_ctrl Std,evaluation/env_infos/reward_run Max,evaluation/env_infos/reward_run Mean,evaluation/env_infos/reward_run Min,evaluation/env_infos/reward_run Std,evaluation/num paths total,evaluation/num steps total,evaluation/path length Max,evaluation/path length Mean,evaluation/path length Min,evaluation/path length Std,exploration/Actions Max,exploration/Actions Mean,exploration/Actions Min,exploration/Actions Std,exploration/Average Returns,exploration/Num Paths,exploration/Returns Max,exploration/Returns Mean,exploration/Returns Min,exploration/Returns Std,exploration/Rewards Max,exploration/Rewards Mean,exploration/Rewards Min,exploration/Rewards Std,exploration/env_infos/final/reward_ctrl Max,exploration/env_infos/final/reward_ctrl Mean,exploration/env_infos/final/reward_ctrl Min,exploration/env_infos/final/reward_ctrl Std,exploration/env_infos/final/reward_run Max,exploration/env_infos/final/reward_run Mean,exploration/env_infos/final/reward_run Min,exploration/env_infos/final/reward_run Std,exploration/env_infos/initial/reward_ctrl Max,exploration/env_infos/initial/reward_ctrl Mean,exploration/env_infos/initial/reward_ctrl Min,exploration/env_infos/initial/reward_ctrl Std,exploration/env_infos/initial/reward_run Max,exploration/env_infos/initial/reward_run Mean,exploration/env_infos/initial/reward_run Min,exploration/env_infos/initial/reward_run Std,exploration/env_infos/reward_ctrl Max,exploration/env_infos/reward_ctrl Mean,exploration/env_infos/reward_ctrl Min,exploration/env_infos/reward_ctrl Std,exploration/env_infos/reward_run Max,exploration/env_infos/reward_run Mean,exploration/env_infos/reward_run Min,exploration/env_infos/reward_run Std,exploration/num paths total,exploration/num steps total,exploration/path length Max,exploration/path length Mean,exploration/path length Min,exploration/path length Std,replay_buffer/size,time/data storing (s),time/epoch (s),time/evaluation sampling (s),time/exploration sampling (s),time/logging (s),time/sac training (s),time/saving (s),time/total (s),time/training (s),trainer/Alpha,trainer/Alpha Loss,trainer/Log Pis Max,trainer/Log Pis Mean,trainer/Log Pis Min,trainer/Log Pis Std,trainer/Policy Loss,trainer/Q Targets Max,trainer/Q Targets Mean,trainer/Q Targets Min,trainer/Q Targets Std,trainer/Q1 Predictions Max,trainer/Q1 Predictions Mean,trainer/Q1 Predictions Min,trainer/Q1 Predictions Std,trainer/Q2 Predictions Max,trainer/Q2 Predictions Mean,trainer/Q2 Predictions Min,trainer/Q2 Predictions Std,trainer/QF1 Loss,trainer/QF2 Loss,trainer/num train calls,trainer/policy/mean Max,trainer/policy/mean Mean,trainer/policy/mean Min,trainer/policy/mean Std,trainer/policy/normal/log_std Max,trainer/policy/normal/log_std Mean,trainer/policy/normal/log_std Min,trainer/policy/normal/log_std Std,trainer/policy/normal/std Max,trainer/policy/normal/std Mean,trainer/policy/normal/std Min,trainer/policy/normal/std Std
0,0.0009271466,5.817112e-06,-0.00093969516,2.4150935e-05,-0.24385504219858278,5,0.33744444190619843,-0.24385504219858278,-0.9488139661957686,0.511236500644291,0.20041059016513815,-0.00024385504219858075,-0.23176297862101286,0.012689332334062916,-1.5076615511588898e-10,-1.5076615511588898e-10,-1.5076615511588898e-10,0.0,2.0816681711721685e-16,-1.3877787807814457e-17,-2.7755575615628914e-16,1.545365047825326e-16,-2.225309714276591e-10,-4.646484086379133e-10,-6.552983933261203e-10,1.522967975447845e-10,0.04440428780244171,-0.018103547115884494,-0.14442881811579253,0.07292568162650967,-6.801812446610712e-11,-3.7008597736587497e-10,-2.1924129214312416e-07,4.173194161621402e-09,0.20041059644137493,-0.00024385467211260342,-0.2317629699648871,0.012689330984844448,5,5000,1000,1000.0,1000,0.0,0.9977235,-0.006921756,-0.99852747,0.6319973,-307.1996178207519,1,-307.1996178207519,-307.1996178207519,-307.1996178207519,0.0,1.6690994304845763,-0.30719961782075195,-2.6075697879450397,0.627123827909341,-0.15707893371582032,-0.15707893371582032,-0.15707893371582032,0.0,0.2369985018171139,0.2369985018171139,0.2369985018171139,0.0,-0.33116376399993896,-0.33116376399993896,-0.33116376399993896,0.0,-0.1649978582371342,-0.1649978582371342,-0.1649978582371342,0.0,-0.02584775984287262,-0.2396811164289713,-0.47649245262146,0.07384231018594435,1.9403476041982604,-0.06751850139178063,-2.269491408313997,0.62184622405815,2,2000,1000,1000.0,1000,0.0,2000,0.00682610203512013,78.23970229551196,2.836554768960923,0.6432437190087512,0.024699059082195163,74.70778968452942,0.02047505893278867,79.48138347209897,0.00011390296276658773,1.0,-0.0,-2.5058203,-3.9851418,-5.2253294,0.5338987,-3.9760513,5.95426,3.5763357,0.75955105,0.82768595,0.0028143106,-0.008343177,-0.024679419,0.0048587853,0.009521447,-0.00376042,-0.023648104,0.0058826967,13.534716,13.502516,1000,0.005310592,-6.257524e-05,-0.0063867085,0.0015184636,0.004839374,-0.00088269636,-0.006222254,0.0014608667,1.0048511,0.9991188,0.99379706,0.0014593686
